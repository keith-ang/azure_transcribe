{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/training_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 27, 460\n",
      "mean / median: 71.13599337524505, 66.0\n",
      "p10 / p90: 47.0, 100.0\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 0, 416\n",
      "mean / median: 35.55436693030487, 31.0\n",
      "p10 / p90: 14.0, 63.0\n",
      "**************************************************\n",
      "Processing file: data/validation_set.jsonl\n",
      "\n",
      "#### Distribution of total tokens:\n",
      "min / max: 32, 325\n",
      "mean / median: 70.9818169528187, 66.0\n",
      "p10 / p90: 47.0, 100.0\n",
      "\n",
      "#### Distribution of assistant tokens:\n",
      "min / max: 0, 276\n",
      "mean / median: 35.40178450723266, 31.0\n",
      "p10 / p90: 14.0, 62.0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\")  # default encoding for gpt-4o models. This requires the latest version of tiktoken to be installed.\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p10 / p90: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['data/training_set.jsonl', 'data/validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        total_tokens = []\n",
    "        assistant_tokens = []\n",
    "        \n",
    "        lines_chunk = []\n",
    "        for line_count, line in enumerate(f, start=1):\n",
    "            lines_chunk.append(line)\n",
    "            if line_count % 5 == 0:\n",
    "                for json_line in lines_chunk:\n",
    "                    try:\n",
    "                        ex = json.loads(json_line)\n",
    "                        messages = ex.get(\"messages\", {})\n",
    "                        total_tokens.append(num_tokens_from_messages(messages))\n",
    "                        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Skipping line due to JSON decode error: {e}\")\n",
    "                lines_chunk = []\n",
    "\n",
    "        # Process remaining lines\n",
    "        if lines_chunk:\n",
    "            for json_line in lines_chunk:\n",
    "                try:\n",
    "                    ex = json.loads(json_line)\n",
    "                    messages = ex.get(\"messages\", {})\n",
    "                    total_tokens.append(num_tokens_from_messages(messages))\n",
    "                    assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Skipping line due to JSON decode error: {e}\")\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 59172\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'You are an expert in CFA finance.'}\n",
      "{'role': 'user', 'content': 'Explain the reclassification of investment property under U.S. GAAP.'}\n",
      "{'role': 'assistant', 'content': 'Under U.S. GAAP, investment property can be reclassified as owner-occupied property.'}\n",
      "\n",
      "Number of examples in validation set: 14794\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'You are an expert in CFA finance.'}\n",
      "{'role': 'user', 'content': 'What were the interest coverage ratios for Nokia and Ericsson in 2008?'}\n",
      "{'role': 'assistant', 'content': 'The interest coverage ratios for 2008 were: - 32.0 for Nokia - 9.6 for Ericsson.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to load a dataset with error handling for invalid JSON\n",
    "def load_dataset(file_path):\n",
    "    dataset = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                dataset.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping line due to JSON decode error: {e}\")\n",
    "    return dataset\n",
    "\n",
    "# Load the training set\n",
    "training_dataset = load_dataset('data/training_set.jsonl')\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "validation_dataset = load_dataset('data/validation_set.jsonl')\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client created\n",
      "Training file ID: file-f74cc3b5bbee4a0ab35f8839488bc8be\n",
      "Validation file ID: file-21f6a6ae0d3c47728eb9e0b66338335a\n"
     ]
    }
   ],
   "source": [
    "# Upload fine-tuning files\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-08-01-preview\"  # This API version or later is required to access seed/events/checkpoint features\n",
    ")\n",
    "\n",
    "print(\"Client created\")\n",
    "\n",
    "training_file_name = 'data/training_set.jsonl'\n",
    "validation_file_name = 'data/validation_set.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client.files.delete(training_file_id)\n",
    "# client.files.delete(validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-b84598f8029240b487e6941abdb166c5\n",
      "Status: pending\n",
      "{\n",
      "  \"id\": \"ftjob-b84598f8029240b487e6941abdb166c5\",\n",
      "  \"created_at\": 1734585249,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": -1,\n",
      "    \"batch_size\": -1,\n",
      "    \"learning_rate_multiplier\": 1\n",
      "  },\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": null,\n",
      "  \"seed\": 105,\n",
      "  \"status\": \"pending\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-f74cc3b5bbee4a0ab35f8839488bc8be\",\n",
      "  \"validation_file\": \"file-21f6a6ae0d3c47728eb9e0b66338335a\",\n",
      "  \"estimated_finish\": 1734588823,\n",
      "  \"integrations\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Submit fine-tuning training job\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model = \"gpt-4o-2024-08-06\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    "    seed = 105 # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")   \n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job ftjob-b84598f8029240b487e6941abdb166c5 finished with status: succeeded\n",
      "Checking other fine-tune jobs for this resource.\n",
      "Found 5 fine-tune jobs.\n"
     ]
    }
   ],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"ftevent-132a09435b2a4372b8bdcbd45c584857\",\n",
      "      \"created_at\": 1734593846,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Training tokens billed: 4091000\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-5a3fb768724c46db90e782361fd2169d\",\n",
      "      \"created_at\": 1734593846,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Model Evaluation Passed.\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-05fdca4a14b44d87891927e09045054a\",\n",
      "      \"created_at\": 1734593846,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Completed results file: file-b28d43822a0e4ba5b615d8e35a7f5d8b\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-24503b4e1abc412c809f15be29d4ddb4\",\n",
      "      \"created_at\": 1734593840,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Postprocessing started.\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-2b2d84de0aba4153885a66c33718cb89\",\n",
      "      \"created_at\": 1734593791,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job succeeded.\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"message\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-808dd1ff898a85e808dd1ff898a85e80\",\n",
      "      \"created_at\": 1734590673,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 1517: training loss=0.9365363121032715\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 1517,\n",
      "        \"train_loss\": 0.9365363121032715,\n",
      "        \"train_mean_token_accuracy\": 0.7586206793785095,\n",
      "        \"valid_loss\": 0.94838609028255,\n",
      "        \"valid_mean_token_accuracy\": 0.7414266117969822,\n",
      "        \"full_valid_loss\": 0.9752685854968671,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7408940906018557\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dd1ff8947c41008dd1ff8947c4100\",\n",
      "      \"created_at\": 1734590666,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 1510: training loss=1.0116103887557983\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 1510,\n",
      "        \"train_loss\": 1.0116103887557983,\n",
      "        \"train_mean_token_accuracy\": 0.744809091091156,\n",
      "        \"valid_loss\": 1.0733423209686466,\n",
      "        \"valid_mean_token_accuracy\": 0.7166462668298653\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dd1ff88e8660008dd1ff88e866000\",\n",
      "      \"created_at\": 1734590656,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 1500: training loss=0.9936316609382629\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 1500,\n",
      "        \"train_loss\": 0.9936316609382629,\n",
      "        \"train_mean_token_accuracy\": 0.7384030222892761,\n",
      "        \"valid_loss\": 0.8990656982183287,\n",
      "        \"valid_mean_token_accuracy\": 0.7711442786069652\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dd1ff888907f008dd1ff888907f00\",\n",
      "      \"created_at\": 1734590646,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 1490: training loss=0.915484607219696\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 1490,\n",
      "        \"train_loss\": 0.915484607219696,\n",
      "        \"train_mean_token_accuracy\": 0.7515316605567932,\n",
      "        \"valid_loss\": 0.7799634755053431,\n",
      "        \"valid_mean_token_accuracy\": 0.7742908871454436\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftevent-008dd1ff8829a9e008dd1ff8829a9e00\",\n",
      "      \"created_at\": 1734590636,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Step 1480: training loss=1.002008080482483\",\n",
      "      \"object\": \"fine_tuning.job.event\",\n",
      "      \"type\": \"metrics\",\n",
      "      \"data\": {\n",
      "        \"step\": 1480,\n",
      "        \"train_loss\": 1.002008080482483,\n",
      "        \"train_mean_token_accuracy\": 0.725895345211029,\n",
      "        \"valid_loss\": 0.9275465097902048,\n",
      "        \"valid_mean_token_accuracy\": 0.7594268476621417\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": true,\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"ftchkpt-fad71355c583415c86f0d6a22b17dd70\",\n",
      "      \"created_at\": 1734593403,\n",
      "      \"fine_tuned_model_checkpoint\": \"gpt-4o-2024-08-06.ft-b84598f8029240b487e6941abdb166c5\",\n",
      "      \"fine_tuning_job_id\": \"ftjob-b84598f8029240b487e6941abdb166c5\",\n",
      "      \"metrics\": {\n",
      "        \"full_valid_loss\": null,\n",
      "        \"full_valid_mean_token_accuracy\": null,\n",
      "        \"step\": 1518.0,\n",
      "        \"train_loss\": 0.6745920181274414,\n",
      "        \"train_mean_token_accuracy\": 0.8134920597076416,\n",
      "        \"valid_loss\": 0.8711808813680516,\n",
      "        \"valid_mean_token_accuracy\": 0.7512376237623762\n",
      "      },\n",
      "      \"object\": \"fine_tuning.job.checkpoint\",\n",
      "      \"step_number\": 1518\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"ftchkpt-8545e078ee1d441bb7cc67941772f96e\",\n",
      "      \"created_at\": 1734593274,\n",
      "      \"fine_tuned_model_checkpoint\": \"gpt-4o-2024-08-06.ft-b84598f8029240b487e6941abdb166c5:ckpt-step-1517\",\n",
      "      \"fine_tuning_job_id\": \"ftjob-b84598f8029240b487e6941abdb166c5\",\n",
      "      \"metrics\": {\n",
      "        \"full_valid_loss\": 0.9752685854968671,\n",
      "        \"full_valid_mean_token_accuracy\": 0.7408940906018557,\n",
      "        \"step\": 1517.0,\n",
      "        \"train_loss\": 0.9365363121032715,\n",
      "        \"train_mean_token_accuracy\": 0.7586206793785095,\n",
      "        \"valid_loss\": 0.94838609028255,\n",
      "        \"valid_mean_token_accuracy\": 0.7414266117969822\n",
      "      },\n",
      "      \"object\": \"fine_tuning.job.checkpoint\",\n",
      "      \"step_number\": 1517\n",
      "    }\n",
      "  ],\n",
      "  \"has_more\": false,\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.checkpoints.list(job_id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"ftjob-b84598f8029240b487e6941abdb166c5\",\n",
      "  \"created_at\": 1734585249,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": \"gpt-4o-2024-08-06.ft-b84598f8029240b487e6941abdb166c5\",\n",
      "  \"finished_at\": 1734593846,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 1,\n",
      "    \"batch_size\": 39,\n",
      "    \"learning_rate_multiplier\": 1\n",
      "  },\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": [\n",
      "    \"file-b28d43822a0e4ba5b615d8e35a7f5d8b\"\n",
      "  ],\n",
      "  \"seed\": 105,\n",
      "  \"status\": \"succeeded\",\n",
      "  \"trained_tokens\": 5943754,\n",
      "  \"training_file\": \"file-f74cc3b5bbee4a0ab35f8839488bc8be\",\n",
      "  \"validation_file\": \"file-21f6a6ae0d3c47728eb9e0b66338335a\",\n",
      "  \"estimated_finish\": 1734588823,\n",
      "  \"integrations\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n",
      "Created\n",
      "{'id': '/subscriptions/c26b1de8-8139-4208-9a48-3cbe4fb007c4/resourceGroups/finetune-model-test/providers/Microsoft.CognitiveServices/accounts/finetune-model-test/deployments/gpt-4o-mini-2024-07-18-ft-test', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'gpt-4o-mini-2024-07-18-ft-test', 'sku': {'name': 'standard', 'capacity': 1}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-4o-2024-08-06.ft-b84598f8029240b487e6941abdb166c5', 'version': '1'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'currentCapacity': 1, 'capabilities': {'area': 'US', 'chatCompletion': 'true', 'jsonSchemaResponse': 'true', 'maxContextToken': '128000', 'maxOutputToken': '16384'}, 'provisioningState': 'Creating'}, 'systemData': {'createdBy': 'kirkjaa@gmail.com', 'createdByType': 'User', 'createdAt': '2024-12-23T03:35:49.8456223Z', 'lastModifiedBy': 'kirkjaa@gmail.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2024-12-23T03:35:49.8456223Z'}, 'etag': '\"eb437365-a35b-40fb-9507-12261c826399\"'}\n"
     ]
    }
   ],
   "source": [
    "# Deploy fine-tuned model\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "token = os.getenv(\"TEMP_AUTH_TOKEN\", \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6InoxcnNZSEhKOS04bWdndDRIc1p1OEJLa0JQdyIsImtpZCI6InoxcnNZSEhKOS04bWdndDRIc1p1OEJLa0JQdyJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC8wNDhhZDkwZC0yZjFlLTQ0OWYtOTIwZS0zMDdhYmNjMDZlMWQvIiwiaWF0IjoxNzM0OTI0NTU5LCJuYmYiOjE3MzQ5MjQ1NTksImV4cCI6MTczNDkyOTAzNiwiYWNyIjoiMSIsImFpbyI6IkFZUUFlLzhZQUFBQXc3UWpOeEl1MExKRitzVDdhWVBaNzhDNGZaMUMxMmJtcW8rWE40NndxdERyNzBMcHlER0ZVMnNnUERBV05qVzN2bFlNaTJPVlVwVXNJRE15TkhoR3hRcEtoZ05DYVp1TzJ4V0pla0NWQXJUWjhkWFp6dktZWXZib3NDcDJXTnF5U3VnNnQ3eW91SUlTSGQ5WDlCVFJnT0J0NldmT2RtZmdiZVc4bWFpci95VT0iLCJhbHRzZWNpZCI6IjE6bGl2ZS5jb206MDAwM0JGRkQxMEMwQkIyMSIsImFtciI6WyJwd2QiLCJtZmEiXSwiYXBwaWQiOiJiNjc3YzI5MC1jZjRiLTRhOGUtYTYwZS05MWJhNjUwYTRhYmUiLCJhcHBpZGFjciI6IjAiLCJlbWFpbCI6ImtpcmtqYWFAZ21haWwuY29tIiwiZmFtaWx5X25hbWUiOiJQYXRodW1hbnVuIiwiZ2l2ZW5fbmFtZSI6IktpcmsiLCJncm91cHMiOlsiMDNmMjU1YTMtNzc2NC00YzQyLTk5ZDYtOGQ4NjZhZTQzOGZhIl0sImlkcCI6ImxpdmUuY29tIiwiaWR0eXAiOiJ1c2VyIiwiaXBhZGRyIjoiMTcyLjE4OC44OC4xNTUiLCJuYW1lIjoiS2lyayBQYXRodW1hbnVuIiwib2lkIjoiN2FhOTIwNjUtM2U0NC00MWY3LThmMzctZTAwNGNlZDc4MWE1IiwicHVpZCI6IjEwMDMyMDAyOEM3OEE4OEQiLCJyaCI6IjEuQVVvQURkbUtCQjR2bjBTU0RqQjZ2TUJ1SFVaSWYza0F1dGRQdWtQYXdmajJNQk11QVJSS0FBLiIsInNjcCI6InVzZXJfaW1wZXJzb25hdGlvbiIsInN1YiI6Ik5JWDdRNHpySFRQUER3bExkb25fWU5UeUJlek1xRkdjUF9JczlFV1dHVGMiLCJ0aWQiOiIwNDhhZDkwZC0yZjFlLTQ0OWYtOTIwZS0zMDdhYmNjMDZlMWQiLCJ1bmlxdWVfbmFtZSI6ImxpdmUuY29tI2tpcmtqYWFAZ21haWwuY29tIiwidXRpIjoiOTVLWnNPMkF3ay02bWlOTmNPM1VBQSIsInZlciI6IjEuMCIsIndpZHMiOlsiNjJlOTAzOTQtNjlmNS00MjM3LTkxOTAtMDEyMTc3MTQ1ZTEwIiwiYjc5ZmJmNGQtM2VmOS00Njg5LTgxNDMtNzZiMTk0ZTg1NTA5Il0sInhtc19lZG92Ijp0cnVlLCJ4bXNfaWRyZWwiOiIxOCAxIiwieG1zX3RjZHQiOjE2ODAwMTg1Mzl9.H3qSIFbGxEzv5Yn2-FSwc8CLmQxTO4MyftpJdEf1RdSElMtUzQ4yVIxQL-WZaEIL2SSo3Ze5YkhMNVK0GdOjgCDOy7AWrTfkqVt-9d6cH0MQPzrBsoon1xGgIQquc7m-ZRzsCsIBuK8xXiFnqsafIBMd_hU_c4r-Ciyg1VM9hy5NO8uGw6BaTNgIgRdPoVUc1KkSb-2d7ejM59m0M0qml8imw0jcc1AXDzcIz4mIqvTF7ecdkYGkbMkgC2uwZZ5ss0XL0kUdD8B2TUdBA4T7GkxdrKOleZdmYRsOmbrt2rLJ85b9VZfoEuoDJO2tZslz8gvRIlgXc35uB34qMltOpQ\") \n",
    "subscription = \"c26b1de8-8139-4208-9a48-3cbe4fb007c4\"\n",
    "resource_group = \"finetune-model-test\"\n",
    "resource_name = \"finetune-model-test\"\n",
    "model_deployment_name = \"gpt-4o-mini-2024-07-18-ft-test\" # Custom deployment name you chose for your fine-tuning model\n",
    "\n",
    "deploy_params = {'api-version': \"2024-10-01\"}\n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"gpt-4o-2024-08-06.ft-b84598f8029240b487e6941abdb166c5\", #retrieve this value from the previous call, it will look like gpt-4o-mini-2024-07-18.ft-0e208cf33a6a466994aff31a08aba678\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Under IFRS, inventory is measured at the lower of cost and net realizable value (NRV). Therefore, the inventory value is $4.1 million (NRV), which is lower than the FIFO cost of $4.3 million. The company must write down the inventory by $0.2 million ($4.3 m - $4.1 m). This write-down would increase the cost of goods sold (COGS), making the COGS $0.2 million higher than compared under US GAAP, where the write-down would be to the current replacement cost of $3.8 million. However, since this option is not given in the answers, none of the provided answers (A, B, C) correctly reflect the situation. Hence, a correct answer should state that COGS is $0.2 million higher when using FIFO under IFRS compared to GAAP if both choices were available.\n"
     ]
    }
   ],
   "source": [
    "# Use the deployed customized model\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-06-01\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini-2024-07-18-ft-test\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in CFA finance.\"},\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": \"\"\"\n",
    "          The following information is available for a manufacturing company:\n",
    "          • Cost of ending inventory computed using FIFO $4.3m\n",
    "          • Net realizable value $4.1m\n",
    "          • Current replacement cost $3.8m\n",
    "\n",
    "          Article continues below\n",
    "          If the company is using International Financial Reporting Standards (IFRS) instead of US GAAP, its cost of goods sold (in millions) is most likely:\n",
    "\n",
    "          A. $0.3 higher.\n",
    "\n",
    "          B. $0.3 lower.\n",
    "\n",
    "          C. the same.\n",
    "        \"\"\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
